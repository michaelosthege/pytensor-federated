import asyncio
import logging
from typing import TYPE_CHECKING, AsyncIterator, Optional, Sequence, Type

import grpclib
import numpy as np
from betterproto import Message, ServiceStub
from grpclib.client import Channel, Stream
from grpclib.metadata import Deadline
from grpclib.stream import _RecvType, _SendType

from .npproto.utils import ndarray_from_numpy, ndarray_to_numpy
from .rpc import (
    ArraysToArraysServiceBase,
    ArraysToArraysServiceStub,
    InputArrays,
    OutputArrays,
)
from .signatures import ComputeFunc

if TYPE_CHECKING:
    from betterproto.grpc.grpclib_client import MetadataLike


_log = logging.getLogger(__file__)


def _run_compute_func(
    func_input: InputArrays,
    func: ComputeFunc,
) -> OutputArrays:
    """Wraps a ``compute_func`` with gRPC message decoding/encoding.

    Parameters
    ----------
    func_input
        InputArrays gRPC message.
    func
        The blackbox function.

    Returns
    -------
    func_output
        OutputArrays gRPC message.
    """
    # Deserialize input arrays
    inputs = [ndarray_to_numpy(i) for i in func_input.items]
    # Run the computation
    outputs = func(*inputs)
    # Encode results
    result = OutputArrays(
        items=[ndarray_from_numpy(o) for o in outputs],
    )
    return result


class ArraysToArraysService(ArraysToArraysServiceBase):
    """Implements a gRPC service around a ``ComputeFunc``."""

    def __init__(
        self,
        compute_func: ComputeFunc,
    ) -> None:
        self._compute_func = compute_func
        super().__init__()

    async def evaluate(
        self,
        input_arrays: InputArrays,
    ) -> OutputArrays:
        return _run_compute_func(input_arrays, self._compute_func)

    async def evaluate_stream(
        self, input_arrays_iterator: AsyncIterator[InputArrays]
    ) -> AsyncIterator[OutputArrays]:
        _log.info("Evaluation stream opened")
        async for input in input_arrays_iterator:
            yield _run_compute_func(input, self._compute_func)
        _log.info("Evaluation stream closed")


async def start_bidirectional_stream(
    *,
    client: ServiceStub,
    route: str,
    request_type: Type[Message],
    response_type: Type[Message],
    timeout: Optional[float] = None,
    deadline: Optional[Deadline] = None,
    metadata: Optional["MetadataLike"] = None,
) -> Stream[_SendType, _RecvType]:
    """Initializes a bidirectional message stream.

    Bidirectional gRPC streams are much faster
    than sending individual non-streamed calls.

    For parameter explanations see ``grpclib.client.Channel.request``.
    """
    # Open the stream
    stream = await client.channel.request(
        route,
        grpclib.const.Cardinality.STREAM_STREAM,
        request_type,
        response_type,
        timeout=client.timeout if timeout is None else timeout,
        deadline=client.deadline if deadline is None else deadline,
        metadata=client.metadata if metadata is None else metadata,
    ).__aenter__()
    # Send the request to start
    await stream.send_request()
    return stream


class ArraysToArraysServiceClient:
    """Wraps the autogenerated gRPC client implementation with a ``ComputeFunc`` signature."""

    def __init__(self, host: str, port: int) -> None:
        """Create a wrapper around the ArraysToArraysOp gRPC client.

        Parameters
        ----------
        host : str
            IP address or host name of the remote gRPC server.
        port : int
            Port of the gRPC server.
        """
        self._channel = Channel(host, port)
        self._client = ArraysToArraysServiceStub(self._channel)
        self._loop = asyncio.get_event_loop()
        self._stream = self._loop.run_until_complete(
            start_bidirectional_stream(
                client=self._client,
                route="/ArraysToArraysService/EvaluateStream",
                request_type=InputArrays,
                response_type=OutputArrays,
            )
        )
        super().__init__()

    def __del__(self):
        # Announce stopping the streaming
        self._stream.end()
        # Close the stream
        self._loop.run_until_complete(self._stream.__aexit__())
        self._channel.close()
        return

    def __call__(self, *inputs: Sequence[np.ndarray]) -> Sequence[np.ndarray]:
        """Alias for ``.evaluate(*inputs)``."""
        return self.evaluate(*inputs)

    def evaluate(self, *inputs: Sequence[np.ndarray], use_stream=True) -> Sequence[np.ndarray]:
        """Evaluate the federated compute function on inputs.

        Parameters
        ----------
        *inputs
            NumPy `ndarray` inputs.
        use_stream : bool
            If ``True`` (default), the RPC is performed through a bidirectional stream,
            which is much faster than sending individual (unary/unary) RPCs.

        Returns
        -------
        *outputs
            Sequence of ``ndarray``s returned by the federated compute function.
        """
        # Encode inputs
        input = InputArrays(items=[ndarray_from_numpy(i) for i in inputs])

        # Make the asynchronous calls to the remote server
        if use_stream:
            eval_task = self._streamed_evaluate(input)
        else:
            eval_task = self._client.evaluate(input)
        output = self._loop.run_until_complete(eval_task)

        # Decode outputs
        outputs = [ndarray_to_numpy(o) for o in output.items]
        return outputs

    async def _streamed_evaluate(self, input: InputArrays) -> OutputArrays:
        """Internal wrapper around async methods of the bidirectional stream."""
        await self._stream.send_message(input)
        response = await self._stream.recv_message()
        assert response is not None
        return response
